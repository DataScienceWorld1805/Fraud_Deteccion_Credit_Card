{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae29de41",
   "metadata": {},
   "source": [
    "Análisis completo de detección de fraude en tarjetas de crédito\n",
    "Incluye EDA completo, preprocesamiento, modelado con XGBoost y métricas detalladas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1d699a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                            roc_auc_score, roc_curve, precision_recall_curve, \n",
    "                            average_precision_score, f1_score, precision_score, recall_score)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4da9fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANÁLISIS DE DETECCIÓN DE FRAUDE - DATASET CREDIT CARD 2023\n",
      "================================================================================\n",
      "\n",
      "1. CARGA DE DATOS\n",
      "--------------------------------------------------------------------------------\n",
      "Shape del dataset: (568630, 31)\n",
      "Columnas: ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n"
     ]
    }
   ],
   "source": [
    "# Configuración de estilo para gráficos\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8-darkgrid')\n",
    "except:\n",
    "    plt.style.use('seaborn-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (15, 10)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Cargar datos\n",
    "print(\"=\"*80)\n",
    "print(\"ANÁLISIS DE DETECCIÓN DE FRAUDE - DATASET CREDIT CARD 2023\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n1. CARGA DE DATOS\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "df = pd.read_csv('Archivos_CSV/creditcard_2023.csv')\n",
    "print(f\"Shape del dataset: {df.shape}\")\n",
    "print(f\"Columnas: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c391d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "2. ANÁLISIS EXPLORATORIO DE DATOS (EDA)\n",
      "================================================================================\n",
      "\n",
      "2.1. Información básica del dataset\n",
      "--------------------------------------------------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 568630 entries, 0 to 568629\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   id      568630 non-null  int64  \n",
      " 1   V1      568630 non-null  float64\n",
      " 2   V2      568630 non-null  float64\n",
      " 3   V3      568630 non-null  float64\n",
      " 4   V4      568630 non-null  float64\n",
      " 5   V5      568630 non-null  float64\n",
      " 6   V6      568630 non-null  float64\n",
      " 7   V7      568630 non-null  float64\n",
      " 8   V8      568630 non-null  float64\n",
      " 9   V9      568630 non-null  float64\n",
      " 10  V10     568630 non-null  float64\n",
      " 11  V11     568630 non-null  float64\n",
      " 12  V12     568630 non-null  float64\n",
      " 13  V13     568630 non-null  float64\n",
      " 14  V14     568630 non-null  float64\n",
      " 15  V15     568630 non-null  float64\n",
      " 16  V16     568630 non-null  float64\n",
      " 17  V17     568630 non-null  float64\n",
      " 18  V18     568630 non-null  float64\n",
      " 19  V19     568630 non-null  float64\n",
      " 20  V20     568630 non-null  float64\n",
      " 21  V21     568630 non-null  float64\n",
      " 22  V22     568630 non-null  float64\n",
      " 23  V23     568630 non-null  float64\n",
      " 24  V24     568630 non-null  float64\n",
      " 25  V25     568630 non-null  float64\n",
      " 26  V26     568630 non-null  float64\n",
      " 27  V27     568630 non-null  float64\n",
      " 28  V28     568630 non-null  float64\n",
      " 29  Amount  568630 non-null  float64\n",
      " 30  Class   568630 non-null  int64  \n",
      "dtypes: float64(29), int64(2)\n",
      "memory usage: 134.5 MB\n",
      "None\n",
      "\n",
      "Valores faltantes por columna:\n",
      "id        0\n",
      "V1        0\n",
      "V2        0\n",
      "V3        0\n",
      "V4        0\n",
      "V5        0\n",
      "V6        0\n",
      "V7        0\n",
      "V8        0\n",
      "V9        0\n",
      "V10       0\n",
      "V11       0\n",
      "V12       0\n",
      "V13       0\n",
      "V14       0\n",
      "V15       0\n",
      "V16       0\n",
      "V17       0\n",
      "V18       0\n",
      "V19       0\n",
      "V20       0\n",
      "V21       0\n",
      "V22       0\n",
      "V23       0\n",
      "V24       0\n",
      "V25       0\n",
      "V26       0\n",
      "V27       0\n",
      "V28       0\n",
      "Amount    0\n",
      "Class     0\n",
      "dtype: int64\n",
      "\n",
      "Total de valores faltantes: 0\n",
      "\n",
      "2.2. Estadísticas descriptivas\n",
      "--------------------------------------------------------------------------------\n",
      "                  id            V1            V2            V3            V4  \\\n",
      "count  568630.000000  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05   \n",
      "mean   284314.500000 -5.638058e-17 -1.319545e-16 -3.518788e-17 -2.879008e-17   \n",
      "std    164149.486122  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
      "min         0.000000 -3.495584e+00 -4.996657e+01 -3.183760e+00 -4.951222e+00   \n",
      "25%    142157.250000 -5.652859e-01 -4.866777e-01 -6.492987e-01 -6.560203e-01   \n",
      "50%    284314.500000 -9.363846e-02 -1.358939e-01  3.528579e-04 -7.376152e-02   \n",
      "75%    426471.750000  8.326582e-01  3.435552e-01  6.285380e-01  7.070047e-01   \n",
      "max    568629.000000  2.229046e+00  4.361865e+00  1.412583e+01  3.201536e+00   \n",
      "\n",
      "                 V5            V6            V7            V8            V9  \\\n",
      "count  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05   \n",
      "mean   7.997245e-18 -3.958636e-17 -3.198898e-17  2.109273e-17  3.998623e-17   \n",
      "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
      "min   -9.952786e+00 -2.111111e+01 -4.351839e+00 -1.075634e+01 -3.751919e+00   \n",
      "25%   -2.934955e-01 -4.458712e-01 -2.835329e-01 -1.922572e-01 -5.687446e-01   \n",
      "50%    8.108788e-02  7.871758e-02  2.333659e-01 -1.145242e-01  9.252647e-02   \n",
      "75%    4.397368e-01  4.977881e-01  5.259548e-01  4.729905e-02  5.592621e-01   \n",
      "max    4.271689e+01  2.616840e+01  2.178730e+02  5.958040e+00  2.027006e+01   \n",
      "\n",
      "       ...           V21           V22           V23           V24  \\\n",
      "count  ...  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05   \n",
      "mean   ...  4.758361e-17  3.948640e-18  6.194741e-18 -2.799036e-18   \n",
      "std    ...  1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00   \n",
      "min    ... -1.938252e+01 -7.734798e+00 -3.029545e+01 -4.067968e+00   \n",
      "25%    ... -1.664408e-01 -4.904892e-01 -2.376289e-01 -6.515801e-01   \n",
      "50%    ... -3.743065e-02 -2.732881e-02 -5.968903e-02  1.590123e-02   \n",
      "75%    ...  1.479787e-01  4.638817e-01  1.557153e-01  7.007374e-01   \n",
      "max    ...  8.087080e+00  1.263251e+01  3.170763e+01  1.296564e+01   \n",
      "\n",
      "                V25           V26           V27           V28         Amount  \\\n",
      "count  5.686300e+05  5.686300e+05  5.686300e+05  5.686300e+05  568630.000000   \n",
      "mean  -3.178905e-17 -7.497417e-18 -3.598760e-17  2.609101e-17   12041.957635   \n",
      "std    1.000001e+00  1.000001e+00  1.000001e+00  1.000001e+00    6919.644449   \n",
      "min   -1.361263e+01 -8.226969e+00 -1.049863e+01 -3.903524e+01      50.010000   \n",
      "25%   -5.541485e-01 -6.318948e-01 -3.049607e-01 -2.318783e-01    6054.892500   \n",
      "50%   -8.193162e-03 -1.189208e-02 -1.729111e-01 -1.392973e-02   12030.150000   \n",
      "75%    5.500147e-01  6.728879e-01  3.340230e-01  4.095903e-01   18036.330000   \n",
      "max    1.462151e+01  5.623285e+00  1.132311e+02  7.725594e+01   24039.930000   \n",
      "\n",
      "          Class  \n",
      "count  568630.0  \n",
      "mean        0.5  \n",
      "std         0.5  \n",
      "min         0.0  \n",
      "25%         0.0  \n",
      "50%         0.5  \n",
      "75%         1.0  \n",
      "max         1.0  \n",
      "\n",
      "[8 rows x 31 columns]\n",
      "\n",
      "2.3. Análisis de la variable objetivo (Class)\n",
      "--------------------------------------------------------------------------------\n",
      "Distribución de clases:\n",
      "Class\n",
      "0    284315\n",
      "1    284315\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Porcentajes:\n",
      "Class\n",
      "0    50.0\n",
      "1    50.0\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Duplicados en el dataset: 0\n",
      "\n",
      "2.4. Análisis de la variable Amount\n",
      "--------------------------------------------------------------------------------\n",
      "Estadísticas de Amount:\n",
      "count    568630.000000\n",
      "mean      12041.957635\n",
      "std        6919.644449\n",
      "min          50.010000\n",
      "25%        6054.892500\n",
      "50%       12030.150000\n",
      "75%       18036.330000\n",
      "max       24039.930000\n",
      "Name: Amount, dtype: float64\n",
      "\n",
      "Skewness de Amount: 0.0017\n",
      "Kurtosis de Amount: -1.1989\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 2. ANÁLISIS EXPLORATORIO DE DATOS (EDA)\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"2. ANÁLISIS EXPLORATORIO DE DATOS (EDA)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 2.1 Información básica\n",
    "print(\"\\n2.1. Información básica del dataset\")\n",
    "print(\"-\"*80)\n",
    "print(df.info())\n",
    "print(f\"\\nValores faltantes por columna:\\n{df.isnull().sum()}\")\n",
    "print(f\"\\nTotal de valores faltantes: {df.isnull().sum().sum()}\")\n",
    "\n",
    "# 2.2 Estadísticas descriptivas\n",
    "print(\"\\n2.2. Estadísticas descriptivas\")\n",
    "print(\"-\"*80)\n",
    "print(df.describe())\n",
    "\n",
    "# 2.3 Análisis de la variable objetivo\n",
    "print(\"\\n2.3. Análisis de la variable objetivo (Class)\")\n",
    "print(\"-\"*80)\n",
    "class_distribution = df['Class'].value_counts()\n",
    "class_percentage = df['Class'].value_counts(normalize=True) * 100\n",
    "print(f\"Distribución de clases:\\n{class_distribution}\")\n",
    "print(f\"\\nPorcentajes:\\n{class_percentage}\")\n",
    "\n",
    "# Verificar si hay duplicados\n",
    "print(f\"\\nDuplicados en el dataset: {df.duplicated().sum()}\")\n",
    "\n",
    "# 2.4 Análisis de la variable Amount\n",
    "print(\"\\n2.4. Análisis de la variable Amount\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Estadísticas de Amount:\\n{df['Amount'].describe()}\")\n",
    "print(f\"\\nSkewness de Amount: {df['Amount'].skew():.4f}\")\n",
    "print(f\"Kurtosis de Amount: {df['Amount'].kurtosis():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34dfbd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "3. GENERANDO VISUALIZACIONES EDA\n",
      "================================================================================\n",
      "[OK] Grafico 1 guardado: 01_distribucion_clases.png\n",
      "[OK] Grafico 2 guardado: 02_distribucion_amount.png\n",
      "\n",
      "Generando análisis de características V1-V28...\n",
      "[OK] Grafico 3 guardado: 03_correlacion_top_features.png\n",
      "[OK] Grafico 4 guardado: 04_distribucion_top_features.png\n",
      "[OK] Grafico 5 guardado: 05_matriz_correlacion.png\n",
      "\n",
      "3.6. Análisis de outliers\n",
      "--------------------------------------------------------------------------------\n",
      "Transacciones con outliers: 241919\n",
      "Fraudes con outliers: 168784\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 3. VISUALIZACIONES EDA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"3. GENERANDO VISUALIZACIONES EDA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Crear directorio para guardar gráficos\n",
    "import os\n",
    "os.makedirs('graficos_eda', exist_ok=True)\n",
    "\n",
    "# 3.1 Distribución de clases\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "class_distribution.plot(kind='bar', ax=axes[0], color=['skyblue', 'coral'])\n",
    "axes[0].set_title('Distribución de Clases (Conteo)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Clase (0=Normal, 1=Fraude)', fontsize=12)\n",
    "axes[0].set_ylabel('Frecuencia', fontsize=12)\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "class_percentage.plot(kind='bar', ax=axes[1], color=['skyblue', 'coral'])\n",
    "axes[1].set_title('Distribución de Clases (Porcentaje)', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Clase (0=Normal, 1=Fraude)', fontsize=12)\n",
    "axes[1].set_ylabel('Porcentaje (%)', fontsize=12)\n",
    "axes[1].tick_params(axis='x', rotation=0)\n",
    "for i, v in enumerate(class_percentage):\n",
    "    axes[1].text(i, v + 0.5, f'{v:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/01_distribucion_clases.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 1 guardado: 01_distribucion_clases.png\")\n",
    "\n",
    "# 3.2 Distribución de Amount por clase\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Boxplot\n",
    "df.boxplot(column='Amount', by='Class', ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Distribución de Amount por Clase (Boxplot)', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Clase', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Amount', fontsize=12)\n",
    "\n",
    "# Histograma\n",
    "df[df['Class']==0]['Amount'].hist(bins=50, ax=axes[0, 1], alpha=0.7, label='Normal', color='skyblue')\n",
    "df[df['Class']==1]['Amount'].hist(bins=50, ax=axes[0, 1], alpha=0.7, label='Fraude', color='coral')\n",
    "axes[0, 1].set_title('Distribución de Amount por Clase (Histograma)', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Amount', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Frecuencia', fontsize=12)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_yscale('log')\n",
    "\n",
    "# Distribución logarítmica\n",
    "df_normal = df[df['Class']==0]['Amount']\n",
    "df_fraud = df[df['Class']==1]['Amount']\n",
    "axes[1, 0].hist(np.log1p(df_normal), bins=50, alpha=0.7, label='Normal', color='skyblue')\n",
    "axes[1, 0].hist(np.log1p(df_fraud), bins=50, alpha=0.7, label='Fraude', color='coral')\n",
    "axes[1, 0].set_title('Distribución de Amount (Log Transform)', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('log(Amount + 1)', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Frecuencia', fontsize=12)\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Estadísticas por clase\n",
    "stats_by_class = df.groupby('Class')['Amount'].agg(['mean', 'median', 'std', 'min', 'max'])\n",
    "stats_by_class.plot(kind='bar', ax=axes[1, 1], width=0.8)\n",
    "axes[1, 1].set_title('Estadísticas de Amount por Clase', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Clase', fontsize=12)\n",
    "axes[1, 1].set_ylabel('Valor', fontsize=12)\n",
    "axes[1, 1].legend(['Media', 'Mediana', 'Desv. Estándar', 'Mínimo', 'Máximo'])\n",
    "axes[1, 1].tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/02_distribucion_amount.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 2 guardado: 02_distribucion_amount.png\")\n",
    "\n",
    "# 3.3 Análisis de características V1-V28\n",
    "print(\"\\nGenerando análisis de características V1-V28...\")\n",
    "v_columns = [col for col in df.columns if col.startswith('V')]\n",
    "\n",
    "# Correlación con la variable objetivo\n",
    "correlations = df[v_columns + ['Amount']].corrwith(df['Class']).sort_values(ascending=False)\n",
    "top_correlations = correlations.head(10)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "top_correlations.plot(kind='barh', ax=ax, color='steelblue')\n",
    "ax.set_title('Top 10 Características más Correlacionadas con Fraude', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Correlación con Class', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/03_correlacion_top_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 3 guardado: 03_correlacion_top_features.png\")\n",
    "\n",
    "# 3.4 Distribución de características más importantes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "top_features = correlations.abs().head(6).index.tolist()\n",
    "\n",
    "for idx, feature in enumerate(top_features):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    df[df['Class']==0][feature].hist(bins=50, ax=axes[row, col], alpha=0.6, label='Normal', color='skyblue', density=True)\n",
    "    df[df['Class']==1][feature].hist(bins=50, ax=axes[row, col], alpha=0.6, label='Fraude', color='coral', density=True)\n",
    "    axes[row, col].set_title(f'Distribución de {feature}', fontsize=12, fontweight='bold')\n",
    "    axes[row, col].set_xlabel(feature, fontsize=10)\n",
    "    axes[row, col].set_ylabel('Densidad', fontsize=10)\n",
    "    axes[row, col].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/04_distribucion_top_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 4 guardado: 04_distribucion_top_features.png\")\n",
    "\n",
    "# 3.5 Matriz de correlación de características más importantes\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "top_15_features = correlations.abs().head(15).index.tolist()\n",
    "correlation_matrix = df[top_15_features + ['Class']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, ax=ax)\n",
    "ax.set_title('Matriz de Correlación - Top 15 Características', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/05_matriz_correlacion.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 5 guardado: 05_matriz_correlacion.png\")\n",
    "\n",
    "# 3.6 Análisis de outliers usando IQR\n",
    "print(\"\\n3.6. Análisis de outliers\")\n",
    "print(\"-\"*80)\n",
    "Q1 = df[v_columns].quantile(0.25)\n",
    "Q3 = df[v_columns].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "outliers = ((df[v_columns] < (Q1 - 1.5 * IQR)) | (df[v_columns] > (Q3 + 1.5 * IQR))).sum(axis=1)\n",
    "df['outlier_count'] = outliers\n",
    "print(f\"Transacciones con outliers: {(df['outlier_count'] > 0).sum()}\")\n",
    "print(f\"Fraudes con outliers: {df[df['Class']==1]['outlier_count'].gt(0).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e32aeda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "4. PREPROCESAMIENTO DE DATOS\n",
      "================================================================================\n",
      "Shape de X: (568630, 29)\n",
      "Shape de y: (568630,)\n",
      "Distribución de clases en y: {0: 284315, 1: 284315}\n",
      "\n",
      "División train-test:\n",
      "Train: 454904 muestras (80.0%)\n",
      "Test: 113726 muestras (20.0%)\n",
      "\n",
      "Distribución en train: {0: 227452, 1: 227452}\n",
      "Distribución en test: {1: 56863, 0: 56863}\n",
      "\n",
      "[OK] Escalado completado (RobustScaler)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. PREPROCESAMIENTO DE DATOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"4. PREPROCESAMIENTO DE DATOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Separar características y variable objetivo\n",
    "X = df.drop(['Class', 'id', 'outlier_count'], axis=1, errors='ignore')\n",
    "y = df['Class']\n",
    "\n",
    "print(f\"Shape de X: {X.shape}\")\n",
    "print(f\"Shape de y: {y.shape}\")\n",
    "print(f\"Distribución de clases en y: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# División train-test estratificada\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nDivisión train-test:\")\n",
    "print(f\"Train: {X_train.shape[0]} muestras ({X_train.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"Test: {X_test.shape[0]} muestras ({X_test.shape[0]/len(df)*100:.1f}%)\")\n",
    "print(f\"\\nDistribución en train: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"Distribución en test: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# Escalado robusto (mejor para datos con outliers)\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "\n",
    "print(\"\\n[OK] Escalado completado (RobustScaler)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e441e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "5. MANEJO DE CLASES DESBALANCEADAS\n",
      "================================================================================\n",
      "Ratio de desbalance (Normal:Fraude): 1.0:1\n",
      "\n",
      "Dataset balanceado - no se aplica SMOTE\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 5. MANEJO DE CLASES DESBALANCEADAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"5. MANEJO DE CLASES DESBALANCEADAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verificar desbalance\n",
    "class_counts = y_train.value_counts()\n",
    "if len(class_counts) > 1:\n",
    "    imbalance_ratio = class_counts.iloc[0] / class_counts.iloc[1]\n",
    "    print(f\"Ratio de desbalance (Normal:Fraude): {imbalance_ratio:.1f}:1\")\n",
    "    \n",
    "    # Aplicar SMOTE solo si hay desbalance significativo (> 5%)\n",
    "    if imbalance_ratio > 1.05 or imbalance_ratio < 0.95:\n",
    "        print(\"\\nAplicando SMOTE para balancear...\")\n",
    "        smote = SMOTE(random_state=42, sampling_strategy=0.5)  # 50% de fraude\n",
    "        X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "        print(f\"Despues de SMOTE:\")\n",
    "        print(f\"Train balanced: {X_train_balanced.shape[0]} muestras\")\n",
    "        print(f\"Distribucion: {pd.Series(y_train_balanced).value_counts().to_dict()}\")\n",
    "    else:\n",
    "        print(\"\\nDataset balanceado - no se aplica SMOTE\")\n",
    "        X_train_balanced = X_train_scaled\n",
    "        y_train_balanced = y_train\n",
    "        imbalance_ratio = 1.0\n",
    "else:\n",
    "    print(\"\\nSolo una clase presente\")\n",
    "    X_train_balanced = X_train_scaled\n",
    "    y_train_balanced = y_train\n",
    "    imbalance_ratio = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dffbeadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "6. ENTRENAMIENTO DEL MODELO XGBOOST\n",
      "================================================================================\n",
      "Entrenando modelo XGBoost...\n",
      "[OK] Modelo entrenado\n",
      "\n",
      "Top 15 características más importantes:\n",
      "   feature  importance\n",
      "13     V14    0.388152\n",
      "9      V10    0.250411\n",
      "3       V4    0.081897\n",
      "16     V17    0.032233\n",
      "11     V12    0.022614\n",
      "2       V3    0.021544\n",
      "7       V8    0.018789\n",
      "0       V1    0.015276\n",
      "1       V2    0.012711\n",
      "10     V11    0.012435\n",
      "17     V18    0.010548\n",
      "12     V13    0.009781\n",
      "8       V9    0.009294\n",
      "20     V21    0.009172\n",
      "19     V20    0.008808\n",
      "[OK] Grafico 6 guardado: 06_importancia_features.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 6. ENTRENAMIENTO DEL MODELO XGBOOST\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"6. ENTRENAMIENTO DEL MODELO XGBOOST\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Configuración de XGBoost optimizado para detección de fraude\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='aucpr',  # AUC-PR es mejor para clases desbalanceadas\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    n_estimators=200,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    min_child_weight=1,\n",
    "    gamma=0.1,\n",
    "    scale_pos_weight=1.0 if imbalance_ratio == 1.0 else imbalance_ratio,  # Maneja desbalance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method='hist'\n",
    ")\n",
    "\n",
    "print(\"Entrenando modelo XGBoost...\")\n",
    "xgb_model.fit(\n",
    "    X_train_balanced, y_train_balanced,\n",
    "    eval_set=[(X_train_scaled, y_train), (X_test_scaled, y_test)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"[OK] Modelo entrenado\")\n",
    "\n",
    "# Importancia de características\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'importance': xgb_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 características más importantes:\")\n",
    "print(feature_importance.head(15))\n",
    "\n",
    "# Visualización de importancia\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "top_20_features = feature_importance.head(20)\n",
    "sns.barplot(data=top_20_features, x='importance', y='feature', ax=ax, palette='viridis')\n",
    "ax.set_title('Top 20 Características más Importantes (XGBoost)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Importancia', fontsize=12)\n",
    "ax.set_ylabel('Característica', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/06_importancia_features.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 6 guardado: 06_importancia_features.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0820b1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "7. PREDICCIONES Y MÉTRICAS\n",
      "================================================================================\n",
      "\n",
      "7.1. Matriz de Confusión:\n",
      "[[56800    63]\n",
      " [    0 56863]]\n",
      "[OK] Grafico 7 guardado: 07_matriz_confusion.png\n",
      "\n",
      "7.2. Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       1.00      1.00      1.00     56863\n",
      "      Fraude       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n",
      "\n",
      "7.3. Métricas Detalladas:\n",
      "--------------------------------------------------------------------------------\n",
      "Precision (Fraude): 0.9989\n",
      "Recall (Sensibilidad): 1.0000\n",
      "F1-Score: 0.9994\n",
      "AUC-ROC: 1.0000\n",
      "AUC-PR (Precision-Recall): 1.0000\n",
      "\n",
      "Accuracy: 0.9994\n",
      "Specificity (Especificidad): 0.9989\n",
      "True Positives (TP): 56863\n",
      "True Negatives (TN): 56800\n",
      "False Positives (FP): 63\n",
      "False Negatives (FN): 0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. PREDICCIONES Y MÉTRICAS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"7. PREDICCIONES Y MÉTRICAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Predicciones\n",
    "y_pred = xgb_model.predict(X_test_scaled)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# 7.1 Matriz de confusión\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\n7.1. Matriz de Confusión:\")\n",
    "print(cm)\n",
    "\n",
    "# Visualización de matriz de confusión\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax, \n",
    "            xticklabels=['Normal', 'Fraude'], yticklabels=['Normal', 'Fraude'])\n",
    "ax.set_title('Matriz de Confusión', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Clase Real', fontsize=12)\n",
    "ax.set_xlabel('Clase Predicha', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/07_matriz_confusion.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 7 guardado: 07_matriz_confusion.png\")\n",
    "\n",
    "# 7.2 Reporte de clasificación\n",
    "print(\"\\n7.2. Reporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraude']))\n",
    "\n",
    "# 7.3 Métricas específicas para fraude\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "auc_pr = average_precision_score(y_test, y_pred_proba)\n",
    "\n",
    "print(\"\\n7.3. Métricas Detalladas:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Precision (Fraude): {precision:.4f}\")\n",
    "print(f\"Recall (Sensibilidad): {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print(f\"AUC-ROC: {auc_roc:.4f}\")\n",
    "print(f\"AUC-PR (Precision-Recall): {auc_pr:.4f}\")\n",
    "\n",
    "# Cálculo de métricas adicionales\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "specificity = TN / (TN + FP)\n",
    "accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy:.4f}\")\n",
    "print(f\"Specificity (Especificidad): {specificity:.4f}\")\n",
    "print(f\"True Positives (TP): {TP}\")\n",
    "print(f\"True Negatives (TN): {TN}\")\n",
    "print(f\"False Positives (FP): {FP}\")\n",
    "print(f\"False Negatives (FN): {FN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05d97097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "8. GUARDANDO MODELO Y SCALER\n",
      "================================================================================\n",
      "[OK] Modelo guardado en: Modelo_Entrenado/modelo_xgboost_fraude.pkl\n",
      "[OK] Scaler guardado en: Modelo_Entrenado/scaler_robust.pkl\n",
      "[OK] Nombres de features guardados en: Modelo_Entrenado/features_names.pkl\n",
      "[OK] Metadatos guardados en: Modelo_Entrenado/metadata_modelo.txt\n",
      "\n",
      "================================================================================\n",
      "MODELO Y ARTEFACTOS GUARDADOS EXITOSAMENTE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 8. GUARDAR MODELO Y SCALER\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"8. GUARDANDO MODELO Y SCALER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs('Modelo_Entrenado', exist_ok=True)\n",
    "\n",
    "# Guardar el modelo XGBoost\n",
    "modelo_path = 'Modelo_Entrenado/modelo_xgboost_fraude.pkl'\n",
    "joblib.dump(xgb_model, modelo_path)\n",
    "print(f\"[OK] Modelo guardado en: {modelo_path}\")\n",
    "\n",
    "# Guardar el scaler\n",
    "scaler_path = 'Modelo_Entrenado/scaler_robust.pkl'\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"[OK] Scaler guardado en: {scaler_path}\")\n",
    "\n",
    "# Guardar lista de columnas (features) para validar inputs\n",
    "features_path = 'Modelo_Entrenado/features_names.pkl'\n",
    "feature_names = X_train.columns.tolist()\n",
    "joblib.dump(feature_names, features_path)\n",
    "print(f\"[OK] Nombres de features guardados en: {features_path}\")\n",
    "\n",
    "# Guardar metadatos del modelo en un archivo de texto\n",
    "metadata_path = 'Modelo_Entrenado/metadata_modelo.txt'\n",
    "with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(\"METADATOS DEL MODELO DE DETECCIÓN DE FRAUDE\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\\n\")\n",
    "    f.write(f\"Fecha de entrenamiento: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Tipo de modelo: XGBoost Classifier\\n\")\n",
    "    f.write(f\"Objetivo: binary:logistic\\n\")\n",
    "    f.write(f\"Métrica de evaluación: aucpr\\n\\n\")\n",
    "    f.write(\"Parámetros del modelo:\\n\")\n",
    "    f.write(f\"  - max_depth: {xgb_model.max_depth}\\n\")\n",
    "    f.write(f\"  - learning_rate: {xgb_model.learning_rate}\\n\")\n",
    "    f.write(f\"  - n_estimators: {xgb_model.n_estimators}\\n\")\n",
    "    f.write(f\"  - subsample: {xgb_model.subsample}\\n\")\n",
    "    f.write(f\"  - colsample_bytree: {xgb_model.colsample_bytree}\\n\\n\")\n",
    "    f.write(\"Rendimiento en conjunto de prueba:\\n\")\n",
    "    f.write(f\"  - Accuracy: {accuracy:.4f}\\n\")\n",
    "    f.write(f\"  - Precision (Fraude): {precision:.4f}\\n\")\n",
    "    f.write(f\"  - Recall (Sensibilidad): {recall:.4f}\\n\")\n",
    "    f.write(f\"  - F1-Score: {f1:.4f}\\n\")\n",
    "    f.write(f\"  - AUC-ROC: {auc_roc:.4f}\\n\")\n",
    "    f.write(f\"  - AUC-PR: {auc_pr:.4f}\\n\\n\")\n",
    "    f.write(f\"Total de features: {len(feature_names)}\\n\")\n",
    "    f.write(f\"Features: {', '.join(feature_names)}\\n\")\n",
    "\n",
    "print(f\"[OK] Metadatos guardados en: {metadata_path}\")\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODELO Y ARTEFACTOS GUARDADOS EXITOSAMENTE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80fcc391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "9. GENERANDO CURVAS DE EVALUACIÓN\n",
      "================================================================================\n",
      "[OK] Grafico 8 guardado: 08_curvas_roc_pr.png\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 9. CURVAS ROC Y PRECISION-RECALL\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"9. GENERANDO CURVAS DE EVALUACIÓN\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Curva ROC\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc_roc\n",
    "\n",
    "# Curva Precision-Recall\n",
    "precision_curve, recall_curve, thresholds_pr = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc_pr\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# ROC Curve\n",
    "axes[0].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "axes[0].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "axes[0].set_xlim([0.0, 1.0])\n",
    "axes[0].set_ylim([0.0, 1.05])\n",
    "axes[0].set_xlabel('False Positive Rate (Especificidad)', fontsize=12)\n",
    "axes[0].set_ylabel('True Positive Rate (Sensibilidad)', fontsize=12)\n",
    "axes[0].set_title('Curva ROC', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(loc=\"lower right\")\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "axes[1].plot(recall_curve, precision_curve, color='darkorange', lw=2, \n",
    "             label=f'PR curve (AUC = {pr_auc:.4f})')\n",
    "baseline = (y_test == 1).sum() / len(y_test)\n",
    "axes[1].axhline(y=baseline, color='navy', lw=2, linestyle='--', label='Baseline (Random)')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Recall (Sensibilidad)', fontsize=12)\n",
    "axes[1].set_ylabel('Precision', fontsize=12)\n",
    "axes[1].set_title('Curva Precision-Recall', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(loc=\"lower left\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('graficos_eda/08_curvas_roc_pr.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"[OK] Grafico 8 guardado: 08_curvas_roc_pr.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5a8be43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "10. VALIDACIÓN CRUZADA ESTRATIFICADA\n",
      "================================================================================\n",
      "\n",
      "Validación Cruzada (5-fold):\n",
      "AUC-PR: 1.0000 (+/- 0.0000)\n",
      "AUC-ROC: 1.0000 (+/- 0.0000)\n",
      "F1-Score: 0.9995 (+/- 0.0003)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 10. VALIDACIÓN CRUZADA\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"10. VALIDACIÓN CRUZADA ESTRATIFICADA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Validación cruzada con AUC-PR\n",
    "cv_scores_aucpr = cross_val_score(\n",
    "    xgb_model, X_train_balanced, y_train_balanced, \n",
    "    cv=skf, scoring='average_precision', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Validación cruzada con AUC-ROC\n",
    "cv_scores_aucroc = cross_val_score(\n",
    "    xgb_model, X_train_balanced, y_train_balanced, \n",
    "    cv=skf, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "\n",
    "# Validación cruzada con F1\n",
    "cv_scores_f1 = cross_val_score(\n",
    "    xgb_model, X_train_balanced, y_train_balanced, \n",
    "    cv=skf, scoring='f1', n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nValidación Cruzada (5-fold):\")\n",
    "print(f\"AUC-PR: {cv_scores_aucpr.mean():.4f} (+/- {cv_scores_aucpr.std() * 2:.4f})\")\n",
    "print(f\"AUC-ROC: {cv_scores_aucroc.mean():.4f} (+/- {cv_scores_aucroc.std() * 2:.4f})\")\n",
    "print(f\"F1-Score: {cv_scores_f1.mean():.4f} (+/- {cv_scores_f1.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fabca863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "11. RESUMEN FINAL\n",
      "================================================================================\n",
      "\n",
      "              Métrica    Valor\n",
      "             Accuracy 0.999446\n",
      "   Precision (Fraude) 0.998893\n",
      "Recall (Sensibilidad) 1.000000\n",
      "          Specificity 0.998892\n",
      "             F1-Score 0.999446\n",
      "              AUC-ROC 0.999980\n",
      "               AUC-PR 0.999978\n",
      "\n",
      "[OK] Resultados guardados en: Archivos_CSV/resultados_modelo.csv\n",
      "[OK] Importancia de caracteristicas guardada en: Archivos_CSV/importancia_features.csv\n",
      "\n",
      "================================================================================\n",
      "ANÁLISIS COMPLETO FINALIZADO\n",
      "================================================================================\n",
      "\n",
      "Gráficos guardados en la carpeta 'graficos_eda/'\n",
      "Resultados del modelo guardados en 'Archivos_CSV/resultados_modelo.csv'\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 11. RESUMEN FINAL Y RESULTADOS\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"11. RESUMEN FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results_summary = {\n",
    "    'Métrica': ['Accuracy', 'Precision (Fraude)', 'Recall (Sensibilidad)', \n",
    "                'Specificity', 'F1-Score', 'AUC-ROC', 'AUC-PR'],\n",
    "    'Valor': [accuracy, precision, recall, specificity, f1, auc_roc, auc_pr]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results_summary)\n",
    "print(\"\\n\" + results_df.to_string(index=False))\n",
    "\n",
    "# Guardar resultados\n",
    "results_df.to_csv('Archivos_CSV/resultados_modelo.csv', index=False)\n",
    "print(\"\\n[OK] Resultados guardados en: Archivos_CSV/resultados_modelo.csv\")\n",
    "\n",
    "# Guardar importancia de características\n",
    "feature_importance.to_csv('Archivos_CSV/importancia_features.csv', index=False)\n",
    "print(\"[OK] Importancia de caracteristicas guardada en: Archivos_CSV/importancia_features.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ANÁLISIS COMPLETO FINALIZADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nGráficos guardados en la carpeta 'graficos_eda/'\")\n",
    "print(\"Resultados del modelo guardados en 'Archivos_CSV/resultados_modelo.csv'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
